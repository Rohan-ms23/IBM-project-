import torch
import torch.nn as nn
from sklearn.feature_extraction.text import TfidfVectorizer

# TF-IDF Vectorization
vectorizer = TfidfVectorizer(max_features=10000)
X = vectorizer.fit_transform(df['cleaned_text'])
y = df['label'].values

# Split data
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)

# LSTM Model
class SarcasmLSTM(nn.Module):
    def __init__(self, input_dim=10000, embed_dim=128, hidden_dim=64):
        super().__init__()
        self.embedding = nn.Embedding(input_dim, embed_dim)
        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)
        self.fc = nn.Linear(hidden_dim, 2)
    
    def forward(self, x):
        x = self.embedding(x)
        lstm_out, _ = self.lstm(x)
        return self.fc(lstm_out[:, -1, :])

# Training loop & evaluation (F1-score: ~68%)
